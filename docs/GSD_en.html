
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Data &#8212; Global Scientific Dialogue</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Technology and Business" href="TechnologyBusiness.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      <img src="_static/fefu.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Global Scientific Dialogue</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="section1.html">
   Global Scientific Dialogue: Introduction For Students
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="tech.html">
   Technology
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Art.html">
   Art and Creativity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Science.html">
   Why Science Matters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Intersubjectivity.html">
   Intersubjectivity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Interdisciplinarity.html">
   Interdisciplinarity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ScientificDialogue.html">
   Scientific Dialogue
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="TechnologyBusiness.html">
   Technology and Business
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Data
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/GSD_en.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FGSD_en.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#big-data">
   88. Big Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-counting">
   89. What is counting?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#senders-and-receivers">
   90. Senders and Receivers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#shannon-information-theory">
   91. Shannon Information Theory
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-information-theory-works">
   92. How Information Theory Works
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#shannon-redundancy">
   93. Shannon Redundancy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probability">
   94. Probability
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ergodicity">
   95. Ergodicity
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="data">
<h1>Data<a class="headerlink" href="#data" title="Permalink to this headline">¶</a></h1>
<div class="section" id="big-data">
<h2>88. Big Data<a class="headerlink" href="#big-data" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<p><strong>KEY QUESTIONS</strong></p>
<ul class="simple">
<li><p>What does Facebook or VK know about you?</p></li>
<li><p>Is big data just counting?</p></li>
<li><p>Can big data be intelligent?</p></li>
</ul>
<p><strong>WHY DOES THIS MATTER?</strong></p>
<ul class="simple">
<li><p>Data analysis, whether the data is big or small is really all about
counting. Typically, ‘big data’ may involve the counting of words or
clicks on a webpage. But what makes ‘big data’ so countable? What,
in fact are we counting? When is one click the same as another?</p></li>
<li><p>The counting that Facebook and other social media companies do does
seem to be remarkably effective. It is able to make prediction about
the social status and economic value of individual users, it is able
to predict how they might vote, and it is able to target them with
advertising that fits their profile.</p></li>
<li><p>Google translate does a remarkable job in converting one language to
another by simply counting words.</p></li>
<li><p>Text analysis software, which Google translate relies on, works by
counting individual words, and groups of words. For example, a
bigram is group of two adjacent words (“the cat”, “cat sat”,
“sat on”), and equally we can count trigrams, with 3 words.</p></li>
<li><p>However, it may be going too far to say that intelligence results
from counting. The counting removes uncertainties about things, and
presents summaries of a person or a translation which may or may not
be correct. However, such summaries are never <em>complete</em>: in any
process of counting, what is not counted is usually the most
important thing.</p></li>
</ul>
</div>
<div class="section" id="what-is-counting">
<h2>89. What is counting?<a class="headerlink" href="#what-is-counting" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<p><strong>KEY QUESTIONS</strong></p>
<ul class="simple">
<li><p>What is exactly the same as something else?</p></li>
<li><p>Can we imagine counting anything outside time?</p></li>
<li><p>Is counting merely a social convention?</p></li>
</ul>
<p><strong>WHY DOES THIS MATTER?</strong></p>
<ul class="simple">
<li><p>The idea of quantifying anything is problematic, and in order to
quantify, a key distinction has to be made about what is the ‘same’
as something else. All quantities are, at some level, <em>relations</em>.</p></li>
<li><p>Bateson argues: “It is impossible, in principle, to explain any
pattern by invoking a single quantity. But note that a ratio between
two quantities is already the beginning of pattern. In others words,
quantity and pattern are of different logical type and do not
readily fit together in the same thinking. “[&#64;bateson_steps_1987]</p></li>
<li><p>Counting is the determination and aggregation of things which are
like one another (analogies), and of surprises - or anomalies.
Analogies are not determinable without the determination of
anomalies. Fundamentally there is a distinction.</p></li>
<li><p>These distinctions have to be agreed - at least between scientists.
If scientists didn’t agree what they were counting then coherent
scientific discourse would not be possible.</p></li>
<li><p>Whenever you see a data analytical report, you should always ask
“What is being counted?”, “What is considered to be the same?”,
“What is considered to be different?”</p></li>
<li><p>Agreement of analogies and anomalies is a conversation between
scientists. Without actual embodied participation in the phenomena
which produce the analogies and anomalies, there is no way of
coordinating the conversation. Without any way of coordinating the
conversation, there is an encroaching mysticism in the whole process
of data analysis.</p></li>
<li><p>Data risks becoming a kind of religion divorced from science.
Education driven by data in this way is also divorced from science.
We end up in the worst-case scenario: an educational system
renouncing the humanities and arts because they are unscientific,
whilst embracing a science which is in the thrall of unreliable data
analysis!</p></li>
</ul>
</div>
<div class="section" id="senders-and-receivers">
<h2>90. Senders and Receivers<a class="headerlink" href="#senders-and-receivers" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<p><strong>KEY QUESTIONS</strong></p>
<ul class="simple">
<li><p>What must a sender do to a message to ensure that it is correctly
received?</p></li>
<li><p>How might the ‘noise’ of the channel of communication be overcome?</p></li>
</ul>
<p><strong>WHY DOES THIS MATTER?</strong></p>
<ul class="simple">
<li><p>Imagine you are trying to communicate to somebody in a noisy room
where there is a distance between you and the other person. What do
you do? Shout? Wave your arms? Text them? Maybe you try all sorts of
things. What you are doing is trying to say the thing you want to
say in many different ways. This is amplification.</p></li>
<li><p>Shannon drew a diagram indicating the basic hurdle of
communication - some kind of amplification was required.</p></li>
<li><p>For Shannon, amplification requires the adding of ‘redundancy’.
Redundancy might mean adding extra bits to the message to ensure
that the differences in entropy between the different symbols would
still be apparent even if the transmission was degraded. To do this,
Shannon argued that <em>redundancy</em> was a critical element in message
transmission.</p></li>
<li><p>If redundancy was added by adding extra bits to the message then it
meant that the bandwidth between the sender and the receiver should
be increased. If redundancy was added through repetition,
transmission would be slower.</p></li>
<li><p>So by calculating the complexity of the message to be sent, the
degradation of the signal on the medium over a distance, and the
amount of redundancy that was needed to be added in order to counter
the effects of degradation, Shannon was able to calculate the
necessary bandwidth for transmission.</p></li>
<li><p>Although he never considered that his mathematical theory was
applicable outside the domain of electronic communication, Shannon’s
theory and ideas about redundancy have been very useful in
understanding human communication.</p></li>
</ul>
<p><img alt="Shannon's basic transduction diagram of communication between senderand receiver[]{label=&quot;ref:shannon&quot;}" src="shannon" />{#ref:shannon
width=”columnwidth”}</p>
</div>
<div class="section" id="shannon-information-theory">
<h2>91. Shannon Information Theory<a class="headerlink" href="#shannon-information-theory" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<p><strong>KEY QUESTIONS</strong></p>
<ul class="simple">
<li><p>Can the meaning of something be calculated?</p></li>
<li><p>Can the information in something be calculated?</p></li>
<li><p>Can knowledge be calculated?</p></li>
</ul>
<p><strong>WHY DOES THIS MATTER?</strong></p>
<ul class="simple">
<li><p>Shannon’s Information theory calculations are detailed in his book
“A Mathematical Theory of Communication”
[&#64;shannon_mathematical_1949]. In this book, he adapted Boltzmann’s
idea of thermodynamic entropy (which was a measure of heat
dispersion) into a measure of the surprisingness of messages
transmitted through a medium.</p></li>
<li><p>Information theory underpins the principles of digital
communication, compression and encryption. Without it, we would not
have the basic mechanics of the internet, let alone the transmission
of video, audio, pictures or text which is carried over it.</p></li>
<li><p>It has found application beyond technology: in biology, Shannon
entropy has been used as an index of biological growth, of ecosystem
development [&#64;odum_fundamentals_1959] and epigenesis
[&#64;deacon_incomplete_2012]; in physics, it is used to explore quantum
mechanics and quantum computing [&#64;results_programming_2007];</p></li>
<li><p>in the social sciences, it is used to explore scientific discourse
and big data [&#64;leydesdorff_knowledge-based_2006]; in geography, it
is used to understand urban development [&#64;haken_information_2015];</p></li>
<li><p>in neuroscience it is used to explore the working of the brain
[&#64;ashby_design_2013]; in anthropology, it is used to explore
cultural behaviour [&#64;bateson_steps_1987]; in the arts, it is used to
explore aesthetics [&#64;kanach_formalized_1992].</p></li>
<li><p>Information theory measures the complexity of a message by
calculating the probability of each event and producing an index of
the ‘average surprisingness’ of a sequence of messages expressed in
terms of the number of ‘bits’ or on-off switches which would be
required to transmit a message of this complexity.</p></li>
<li><p>Information is not the same a meaning. Shannon never believed that
meaning could be understood through his theory, although other
theorists (including Shannon’s collaborator, Warren Weaver) do
believe that deeper issues of meaning can be understood in this way.</p></li>
</ul>
<p><img alt="image" src="_images/shannonpic.jpg" /></p>
</div>
<div class="section" id="how-information-theory-works">
<h2>92. How Information Theory Works<a class="headerlink" href="#how-information-theory-works" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<p><strong>KEY QUESTIONS</strong></p>
<ul class="simple">
<li><p>How does Information Theory provide an index to complexity?</p></li>
<li><p>Why is it useful?</p></li>
</ul>
<p><strong>WHY DOES THIS MATTER?</strong></p>
<ul>
<li><p>Consider a very simple message:</p>
<blockquote>
<div><p>A A A A A A A A</p>
</div></blockquote>
<p>For each symbol in a message, we can calculate its surprisingness by
multiplying its probability by the <span class="math notranslate nohighlight">\(log_2\)</span> of its probability. The
total surprisingness of the message is the sum of this calculation
for all the different symbols which appear. With 8 A’s, the number
of symbols is 1, and the probability of A appearing is 1. The <span class="math notranslate nohighlight">\(log\)</span>
of 1 is 0, therefore, the surprisingness of the message is
<span class="math notranslate nohighlight">\(1 times 0 = 0\)</span>.</p>
</li>
<li><p>Now consider this sequence:</p>
<blockquote>
<div><p>A A B A A A A B</p>
</div></blockquote>
<p>Here, there are two symbols, so we calculate the probability of each
symbol and multiply it by the <span class="math notranslate nohighlight">\(log\)</span> of the probability of each
symbol. So the probability of A is <span class="math notranslate nohighlight">\(frac{6}{8}\)</span> and the probability
of B is <span class="math notranslate nohighlight">\(frac{2}{8} = frac{1}{4}\)</span>. Information theory calculates
<span class="math notranslate nohighlight">\(log\)</span>s to base 2. This is because in digital signals, something can
be either <em>on</em> or <em>off</em>. Shannon’s central problem which he sought
to address was how many <em>on/off</em> switches would be required to
transmit a particular message with a particular degree of
surprisingness. There had to be enough switches to generate the
<em>variety</em> of different symbols that were required to be sent.</p>
<p>So we can use <span class="math notranslate nohighlight">\(log_2\)</span> to calculate <span class="math notranslate nohighlight">\(log_2 frac{6}{8} = -0.415\)</span> and
<span class="math notranslate nohighlight">\(log_2 frac{1}{4} = -2\)</span>. Now we multiply these <span class="math notranslate nohighlight">\(log\)</span> values with
the probability of those values to give
<span class="math notranslate nohighlight">\(frac{6}{8} times -0.415 = -0.311\)</span> and
<span class="math notranslate nohighlight">\(frac{1}{4} times -2 = 0.5\)</span>. Adding them together gives <span class="math notranslate nohighlight">\(-0.811\)</span>.
So the addition of an extra symbol produces quite a jump in entropy.
Note, if there was only one B in a sea of A’s, then the average
surprisingness would be <em>higher</em>: <span class="math notranslate nohighlight">\(log_2frac{1}{8} = -3\)</span> and
<span class="math notranslate nohighlight">\(log_2frac{7}{8} = -0.192\)</span>, and multiplying these by the
probabilities gives: <span class="math notranslate nohighlight">\(frac{1}{8} times -3 = -0.375\)</span> and
<span class="math notranslate nohighlight">\(frac{7}{8} times -0.192 = -0.168\)</span> giving a total of <span class="math notranslate nohighlight">\(0.543\)</span>.</p>
</li>
</ul>
</div>
<div class="section" id="shannon-redundancy">
<h2>93. Shannon Redundancy<a class="headerlink" href="#shannon-redundancy" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<p><strong>KEY QUESTIONS</strong></p>
<ul class="simple">
<li><p>Is saying the same thing many times, in many different ways a waste
or a necessity?</p></li>
<li><p>How much of life is repetition?</p></li>
</ul>
<p><strong>WHY DOES THIS MATTER?</strong></p>
<ul class="simple">
<li><p>Redundancy basically means repeating something. However, things can
be repeated in different ways: you can send a text, make a phone
call, send a letter, make a video, etc.</p></li>
<li><p>Redundancy is important because it is the way in which we try to
ensure that a message is sent successfully and its meaning is
understood.</p></li>
<li><p>In Shannon information theory, the challenge was to send a message
over a ‘noisy’ medium (think of a noisy room). In Shannon’s theory,
this might mean repeating the message, adding extra bits to check
the transmission, or to present the same message in a different way.
In fact, whichever technique is used, redundancy amounts to
<em>creating alternative descriptions of the same thing</em>.</p></li>
<li><p>When we talk to each other, very often the same idea gets expressed
in many different ways. The act of teaching is about finding many
ways in which a concept can be explained (‘think about it like
this’, ‘do this exercise’, ‘let me tell you a story…’)</p></li>
<li><p>In Shannon’s theory, redundancy is a way of thinking about the rules
which say that some symbols are used more often than others. In
language, this is called a grammar. Once somebody knows the grammar,
messages are more easily understood.</p></li>
<li><p>Redundancy is the inverse of information. If information is the
‘figure’, redundancy is the ‘background’.</p></li>
</ul>
<p><img alt="image" src="_images/gestalt_figure_ground.jpg" /></p>
</div>
<div class="section" id="probability">
<h2>94. Probability<a class="headerlink" href="#probability" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<p><strong>KEY QUESTIONS</strong></p>
<ul class="simple">
<li><p>What is the difference between the chance of rolling a 6 with dice,
and the chance of it raining tomorrow?</p></li>
<li><p>If you are told you have a 2% chance of having a heart attack, what
does that mean?</p></li>
<li><p>Is improbability the same as surprisingness?</p></li>
</ul>
<p><strong>WHY DOES THIS MATTER?</strong></p>
<ul class="simple">
<li><p>The mathematical theory of probability focuses on those situations,
such as games, where the number of possible options is clearly
known.</p></li>
<li><p>Many events in daily life do not have this property: the number of
possible factors and options is often unknown.</p></li>
<li><p>Some things which might be described as ‘improbable’ are
‘surprising’. However, what is perceived as surprising might be
subjective ignorance rather than objective probability.</p></li>
<li><p>However in modern statistics and game theory, uncertainties over the
maximum number of possible events is often overlooked: instead real
situations are treated like abstract ‘game’ situations.</p></li>
<li><p>The problem of surprisingness is related to the issue of induction:
that if something has happened before, it becomes more likely to
happen again. Again, this assumption can be unreliable.</p></li>
<li><p>Probability is very important in quantum mechanics because there is
no certainty about the position of a subatomic particle until it is
observed. Therefore, the position of the particle is represented by
a ‘wave function’ which is effectively a map of the probabilities of
the particle at different positions. These probability distributions
are, however, accurate in making predictions - a feature that has
been exploited in quantum computing.</p></li>
</ul>
<p><img alt="image" src="_images/probability.png" /></p>
</div>
<div class="section" id="ergodicity">
<h2>95. Ergodicity<a class="headerlink" href="#ergodicity" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<p><strong>KEY QUESTION</strong></p>
<ul class="simple">
<li><p>Is the complexity of something over a period of time the same as the
complexity of that thing over a different period of time?</p></li>
<li><p>What is the difference in complexity from one period of time to
another?</p></li>
<li><p>How does complexity change?</p></li>
</ul>
<p><strong>WHY DOES THIS MATTER?</strong></p>
<ul>
<li><p>Ergodicity is a statistical property of system whereby a measure of
its behaviour over a particular time period is seen to be the same
as a measure of its behaviour over a long period. It’s often used in
information theory as a way of describing the Shannon entropy of a
system over one period of time to another. For example, Shannon
measured the entropy of the English language as a distribution of
letters. This measurement is ergodic to the extent that the shorter
sample contains a representative sample of the grammar and syntax of
the language, and that over a larger sample the value of the entropy
of the language is no different.</p></li>
<li><p>The principles of ergodicity rely on some assumptions:</p>
<ul class="simple">
<li><p>the “alphabet” of what is counted is made explicit at the
beginning and does not change.</p></li>
<li><p>the constraints which determine the distribution of symbols do
not change</p></li>
</ul>
<p>Shannon’s reticence to apply information theory to the study of
meaning, or the more profound features of living systems rested, I
believe, on the fact that he knew that with living systems, neither
of these assumptions about ergodicity are true.</p>
</li>
<li><p>Living systems do not present a complete countable “alphabet” of
things to count at the outset. Countable things are emergent: before
you have fingers, you have cells. Partly this is because the second
assumption is wrong - the constraints within which living things
grow and adapt are continually changing. Indeed, the very process of
life is a process of auto-generating constraint - what the
biologists call “autocatalysis”.</p></li>
<li><p>Learning, for example, is part of a living process. Learning
conversations are rather like dances where nobody quite knows the
rules, and indeed, the rules change as it goes along. But somehow
the whole thing has coherence. This is a mystery which I believe the
analysis of music can help illuminate. Both music and learning
conversations develop by creating new constraints and emerging new
significant (countable) things. The dynamics and effectiveness of a
learning conversation, as a piece of music, rests on how those
constraints interact. It turns out that each new expression is a
redundant expression - it says something that has already been said
before but in a different way.</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="TechnologyBusiness.html" title="previous page">Technology and Business</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By The Jupyter Book community<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>